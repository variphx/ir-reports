\section{Ý tưởng}
Trong một hệ thống truy xuất thông tin hiện đại vận hành theo định hướng mạng nơ-ron, việc tích hợp BERT làm thành phần lõi cho quy trình tạo và khai thác nhúng không chỉ là lựa chọn kỹ thuật mà còn là bước chuyển mình mang tính chiến lược nhằm khai thác chiều sâu ngữ nghĩa từ văn bản tự nhiên. Workflow của hệ thống này được kiến tạo thành một chuỗi các bước có tổ chức chặt chẽ, nơi mỗi thành tố đóng vai trò quyết định trong việc đảm bảo rằng thông tin truy xuất được thực sự phản ánh đúng mối liên hệ ngữ nghĩa giữa truy vấn và tài liệu.

Bắt đầu từ bước chuẩn bị và tiền xử lý, dữ liệu đầu vào -- thường là văn bản thô từ nhiều nguồn -- được xử lý để loại bỏ nhiễu, chuẩn hóa biểu đạt, và duy trì tính toàn vẹn ngữ cảnh. Việc này không chỉ là hành động làm sạch dữ liệu đơn thuần mà còn là giai đoạn đầu tiên trong việc định hình ngữ nghĩa mà hệ thống sẽ tiếp nhận. Ngay sau đó, các văn bản được phân đoạn thành những đơn vị nhỏ hơn, thường là các câu hoặc đoạn văn, phù hợp với giới hạn dung lượng mà BERT có thể xử lý hiệu quả trong một lượt biểu diễn. Phân đoạn không chỉ giúp tiết kiệm tài nguyên tính toán, mà còn giúp nâng cao độ chính xác của việc ánh xạ ngữ nghĩa bằng cách tránh hiện tượng loãng thông tin xảy ra ở các văn bản dài.

Ở bước kế tiếp, từng đoạn văn bản đã qua xử lý được đưa vào mô hình BERT để sinh ra nhúng. Quá trình này bắt đầu bằng việc token hóa văn bản thành các đơn vị ngữ nghĩa nhỏ hơn, sau đó các token được ánh xạ lên không gian vector thông qua các tầng encoder của mô hình. Các nhúng thu được, thường có kích thước cao (chẳng hạn 768 chiều đối với BERT cơ sở), chính là biểu diễn toán học cô đọng của nội dung ngữ nghĩa -- các vector này giữ vai trò nền tảng cho toàn bộ quá trình truy xuất phía sau. Để đảm bảo khả năng truy cập nhanh và hiệu quả ở quy mô lớn, tất cả các vector được lưu trữ trong một hệ thống cơ sở dữ liệu vector chuyên biệt như FAISS, nơi cung cấp khả năng tìm kiếm theo mức độ tương đồng gần như tức thời.

Khi một truy vấn được người dùng nhập vào, hệ thống tiến hành xử lý nó qua cùng pipeline như với tài liệu: từ làm sạch, phân đoạn, token hóa, đến biểu diễn bằng BERT. Việc tái sử dụng cùng một mô hình BERT bảo đảm rằng vector biểu diễn của truy vấn và của tài liệu cùng tồn tại trong một không gian ngữ nghĩa nhất quán, từ đó làm cơ sở cho việc đo lường mức độ tương đồng một cách chính xác. Nhúng truy vấn sau đó được sử dụng để tìm kiếm trong kho vector, nơi các phép đo như cosine similarity được áp dụng để xếp hạng các tài liệu dựa trên độ gần ngữ nghĩa so với truy vấn.

Quá trình này có thể được tinh chỉnh thêm với các bước giảm chiều như PCA hoặc t-SNE nhằm tối ưu hóa lưu trữ và cải thiện hiệu suất xử lý ở giai đoạn truy xuất, mà không làm mất đi các đặc trưng ngữ nghĩa cốt lõi. Tuy nhiên, điều đáng nhấn mạnh là thành công của hệ thống không chỉ đến từ mô hình BERT như một khối xây dựng độc lập, mà là sự tổng hòa của toàn bộ kiến trúc -- từ pipeline tiền xử lý, cơ chế tạo nhúng, cấu trúc lưu trữ vector, đến kỹ thuật truy xuất hiệu quả.

Do đó, trong thực tiễn triển khai, hệ thống IR xoay quanh BERT là một thực thể phức hợp, nơi mỗi bước trong workflow không chỉ thực hiện một chức năng riêng biệt, mà còn gắn kết chặt chẽ với nhau để hình thành nên một dòng chảy ngữ nghĩa xuyên suốt, từ dữ liệu đầu vào đến kết quả truy xuất đầu ra. Đây chính là biểu hiện rõ nét của việc đưa học sâu vào trung tâm của truy xuất thông tin, không chỉ như một công cụ kỹ thuật, mà như một khung nhận thức mới cho việc hiểu và tái cấu trúc tri thức từ văn bản.
